{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e18b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45950936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_env_inc_skip import TrajComp\n",
    "from rl_brain import PolicyGradient\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_online(env, RL, ratio, elist): # Validation\n",
    "    eva = []\n",
    "    skip_pts = 0\n",
    "    step_pts = 0\n",
    "    for episode in elist:\n",
    "        buffer_size = int(ratio*len(env.ori_traj_set[episode]))\n",
    "        if buffer_size < 3:\n",
    "            continue\n",
    "        steps, observation = env.reset(episode, buffer_size)\n",
    "        step_pts = step_pts + steps\n",
    "        for index in range(buffer_size, steps):\n",
    "            if index == steps - 1:\n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "            if index < env.INX:\n",
    "                #print('test skip')\n",
    "                skip_pts = skip_pts + 1\n",
    "                continue\n",
    "            action = RL.pro_choose_action(observation)\n",
    "            observation_, _ = env.step(episode, action, index, done, 'V') #'T' means Training, and 'V' means Validation\n",
    "            observation = observation_\n",
    "        eva.append(env.output(episode, 'V')) #'T' means Training, 'V' means Validation, and 'V-VIS' for visualization on Validation\n",
    "    return eva\n",
    "        \n",
    "def run_comp(env, RL, Round, traj_amount, valid_amount, show_time, ratio): #Training\n",
    "    check = 999999\n",
    "    tra_av_errs = []#放的是每50回合训练集上的平均误差\n",
    "    val_av_errs = []#放的是每50回合验证集上的平均误差\n",
    "    for r in range(Round):\n",
    "        env.shuffle()\n",
    "        episode = 0\n",
    "        for i in range(0, traj_amount, show_time):\n",
    "            train_ep_errs = []\n",
    "            start_t = time.time()\n",
    "            for _ in tqdm(range(show_time), desc=\"[{}/{}]\".format(min(i+show_time,traj_amount),traj_amount),ncols=100):\n",
    "                buffer_size = int(ratio*len(env.ori_traj_set[episode]))\n",
    "                # extreme cases\n",
    "                if buffer_size < 3:\n",
    "                    episode += 1\n",
    "                    continue\n",
    "                steps, state = env.reset(episode, buffer_size)#初始化状态值，返回轨迹点数和有序列表前k个状态值\n",
    "                for index in range(buffer_size, steps):#从第一次缓存外第一个点遍历到最后一个点\n",
    "                    if index == steps - 1:#如果已经是轨迹最后一个点\n",
    "                        done = True\n",
    "                    else:\n",
    "                        done = False\n",
    "                    if index < env.INX:\n",
    "                        #print('train skip')\n",
    "                        continue\n",
    "                    action = RL.pro_choose_action(state)#状态输出到神经网络输出动作的概率分布，按概率采样一个动作\n",
    "                    new_state, reward = env.step(episode, action, index, done, 'T') #'T' means Training, and 'V' means Validation                   \n",
    "                    RL.store_transition(state, action, reward)\n",
    "                    if done:\n",
    "                        RL.learn()#回合结束开始策略梯度算法学习参数\n",
    "                        break\n",
    "                    state = new_state\n",
    "                train_e = env.output(episode, 'T') #'T' means Training, 'V' means Validation, and 'V-VIS' for visualization on Validation\n",
    "                train_ep_errs.append(train_e)\n",
    "                episode += 1\n",
    "            \n",
    "            val_ep_errs = run_online(env, RL, ratio, [i for i in range(traj_amount, traj_amount + valid_amount)])\n",
    "            val_av_err = sum(val_ep_errs)/len(val_ep_errs)\n",
    "            val_av_errs.append(val_av_err)\n",
    "            tra_av_err = sum(train_ep_errs)/len(train_ep_errs)\n",
    "            tra_av_errs.append(tra_av_err)\n",
    "            print('round {} episode {}: Training error: {}, Validation error: {}'.format(r, episode, tra_av_err, val_av_err))\n",
    "            if val_av_err < check:\n",
    "                check = val_av_err\n",
    "                RL.save('./save_skip_multitrain/'+ str(val_av_err) + '_ratio_' + str(ratio) + '_' + env.label + '/trained_model.ckpt')\n",
    "                print('Save model with error {}'.format(val_av_err))\n",
    "            print('==>current best model is {} with ratio {}'.format(check, ratio))\n",
    "            print('It costs {}s'.format(time.time()-start_t))\n",
    "    return tra_av_errs, val_av_errs\n",
    "\n",
    "def train(traj_amount, valid_amount, Round, show_time, ratio, a_size, s_size, skip_size, label):\n",
    "    traj_path = '../trajData/Geolife_out/'\n",
    "    env = TrajComp(a_size + skip_size, s_size)\n",
    "    env.load_train_data(traj_path, traj_amount, valid_amount)\n",
    "    env.set_error_type(label)\n",
    "    RL = PolicyGradient(env.n_features, env.n_actions)\n",
    "    start = time.time()\n",
    "    tra_av_errs, val_av_errs = run_comp(env, RL, Round, traj_amount, valid_amount, show_time, ratio)\n",
    "    print(\"Training elapsed time = %s\", float(time.time() - start))\n",
    "    with open('errors_records.txt', 'a') as f:\n",
    "        f.write('\\nTraining errors and validation errors (' + label + ')\\n')\n",
    "        for i in range(len(tra_av_errs)):\n",
    "            f.write(str(tra_av_errs[i])+' ')\n",
    "        f.write('\\n')\n",
    "        for i in range(len(val_av_errs)):\n",
    "            f.write(str(val_av_errs[i])+' ')\n",
    "    plt.figure()\n",
    "    plt.title(\"Average errors of training and validation:\")\n",
    "    plt.xlabel(\"training process / \"+str(show_time)+\" episodes\")\n",
    "    plt.ylabel(label+\" error\")\n",
    "    x = range(len(tra_av_errs))\n",
    "    plt.plot(x, tra_av_errs, \"r\", label=\"training\" )\n",
    "    plt.plot(x, val_av_errs, \"b\", label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.title(\"Average errors of validation:\")\n",
    "    plt.xlabel(\"training process / \"+str(show_time)+\" episodes\")\n",
    "    plt.ylabel(label+\" error\")\n",
    "    x = range(len(tra_av_errs))\n",
    "    plt.plot(x, val_av_errs, \"b\", label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def retrain(model_path, traj_amount, valid_amount, Round, show_time, ratio, a_size, s_size, skip_size, label):\n",
    "    traj_path = '../trajData/Geolife_out/'\n",
    "    env = TrajComp(a_size + skip_size, s_size)\n",
    "    env.load_train_data(traj_path, traj_amount, valid_amount)\n",
    "    env.set_error_type(label)\n",
    "    RL = PolicyGradient(env.n_features, env.n_actions)\n",
    "    RL.load(model_path)\n",
    "    start = time.time()\n",
    "    tra_av_errs, val_av_errs = run_comp(env, RL, Round, traj_amount, valid_amount, show_time, ratio)\n",
    "    print(\"Training elapsed time = %s\", float(time.time() - start))\n",
    "    with open('errors_records.txt', 'a') as f:\n",
    "        f.write('\\nTraining errors and validation errors (' + label + ')\\n')\n",
    "        for i in range(len(tra_av_errs)):\n",
    "            f.write(str(tra_av_errs[i])+' ')\n",
    "        f.write('\\n')\n",
    "        for i in range(len(val_av_errs)):\n",
    "            f.write(str(val_av_errs[i])+' ')\n",
    "    plt.figure()\n",
    "    plt.title(\"Average errors of training and validation:\")\n",
    "    plt.xlabel(\"training process / \"+str(show_time)+\" episodes\")\n",
    "    plt.ylabel(label+\" error\")\n",
    "    x = range(len(tra_av_errs))\n",
    "    plt.plot(x, tra_av_errs, \"r\", label=\"training\" )\n",
    "    plt.plot(x, val_av_errs, \"b\", label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.title(\"Average errors of validation:\")\n",
    "    plt.xlabel(\"training process / \"+str(show_time)+\" episodes\")\n",
    "    plt.ylabel(label+\" error\")\n",
    "    x = range(len(tra_av_errs))\n",
    "    plt.plot(x, val_av_errs, \"b\", label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "from rl_env_inc_skip import TrajComp\n",
    "from rl_brain import PolicyGradient\n",
    "import data_utils as F\n",
    "import time\n",
    "\n",
    "def evaluate(env, RL, ratio, elist): # Evaluation\n",
    "    eva = []\n",
    "    skip_pts = 0\n",
    "    step_pts = 0\n",
    "    for episode in elist:\n",
    "        buffer_size = int(ratio*len(env.ori_traj_set[episode]))\n",
    "        if buffer_size < 3:\n",
    "            continue\n",
    "        steps, observation = env.reset(episode, buffer_size)\n",
    "        step_pts = step_pts + steps\n",
    "        for index in range(buffer_size, steps):\n",
    "            if index == steps - 1:\n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "            if index < env.INX:\n",
    "                #print('test skip')\n",
    "                skip_pts = skip_pts + 1\n",
    "                continue\n",
    "            action = RL.quick_time_action(observation)\n",
    "            observation_, _ = env.step(episode, action, index, done, 'V') #'T' means Training, and 'V' means Validation\n",
    "            observation = observation_\n",
    "        eva.append(env.output(episode, 'V')) #'T' means Training, 'V' means Validation, and 'V-VIS' for visualization on Validation\n",
    "    return sum(eva)/len(eva)\n",
    "\n",
    "def test(model_path, amount, ratio, a_size, s_size, skip_size, label):\n",
    "    print(\"======Start testing the model at'{}======'\".format(model_path))\n",
    "    traj_path = '../trajData/Geolife_out/'\n",
    "    env = TrajComp(a_size + skip_size, s_size)\n",
    "    env.load_test_data(traj_path, amount)\n",
    "    env.set_error_type(label)\n",
    "    rl = PolicyGradient(env.n_features, env.n_actions)\n",
    "    rl.load(model_path) #your_trained_model your_trained_model_skip\n",
    "    for _ in range(3):\n",
    "        start = time.time()\n",
    "        effectiveness = evaluate(env, rl, ratio, range(amount))\n",
    "        print(\"Effectiveness: {:.4f}\".format(effectiveness))\n",
    "        print(\"Training elapsed time = {:.4f}s\".format(float(time.time() - start)))   \n",
    "\n",
    "def test_err(model_path, amount, ratio, a_size, s_size, skip_size):\n",
    "    print(\"======Start testing the model at'{}======'\".format(model_path))\n",
    "    traj_path = '../trajData/Geolife_out/'\n",
    "    env = TrajComp(a_size + skip_size, s_size)\n",
    "    env.load_test_data(traj_path, amount)\n",
    "    rl = PolicyGradient(env.n_features, env.n_actions)\n",
    "    rl.load(model_path) #your_trained_model your_trained_model_skip\n",
    "    for _ in range(3):\n",
    "        errs = []\n",
    "        t = []\n",
    "        for type in ['sed','ped','dad','sad']:\n",
    "            env.set_error_type(type)\n",
    "            st = time.time()\n",
    "            err = evaluate(env, rl, ratio, range(amount))\n",
    "            t.append(time.time()-st)\n",
    "            errs.append(err)\n",
    "        print(\"Effectiveness of different errors: sed:{:.4f}, ped:{:.4f}, dad:{:.4f}, sad:{:.4f}\"\\\n",
    "              .format(errs[0],errs[1],errs[2],errs[3]))\n",
    "        print(\"Testing elapsed time = {:.4f}s, {:.4f}s, {:.4f}s, {:.4f}s\".format(t[0],t[1],t[2],t[3]))\n",
    "        \n",
    "def test_ratio(model_path, amount, a_size, s_size, skip_size, label):\n",
    "    print(\"======Start testing the model at'{}======'\".format(model_path))\n",
    "    traj_path = '../trajData/Geolife_out/'\n",
    "    env = TrajComp(a_size + skip_size, s_size)\n",
    "    env.load_test_data(traj_path, amount)\n",
    "    rl = PolicyGradient(env.n_features, env.n_actions)\n",
    "    rl.load(model_path) #your_trained_model your_trained_model_skip\n",
    "    for _ in range(3):\n",
    "        errs = []\n",
    "        t = []\n",
    "        for r in [0.1,0.2,0.3,0.4,0.5]:\n",
    "            env.set_error_type(label)\n",
    "            st = time.time()\n",
    "            err = evaluate(env, rl, r, range(amount))\n",
    "            t.append(time.time()-st)\n",
    "            errs.append(err)\n",
    "        print(\"Effectiveness of different ratios: 0.1:{:.4f}, 0.2:{:.4f}, 0.3:{:.4f}, 0.4:{:.4f}, 0.5:{:.4f}\"\\\n",
    "              .format(errs[0],errs[1],errs[2],errs[3],errs[4]))\n",
    "        print(\"Testing elapsed time = {:.4f}s, {:.4f}s, {:.4f}s, {:.4f}s, {:.4f}s\".format(t[0],t[1],t[2],t[3],t[4]))\n",
    "\n",
    "def test_one_sample(model_path, index, ratio, a_size, s_size, skip_size, label):\n",
    "    print(\"======Start testing the model at'{}======'\".format(model_path))\n",
    "    traj_path = '../trajData/Geolife_out/'\n",
    "    env = TrajComp(a_size + skip_size, s_size)\n",
    "    env.load_one_sample(traj_path, index)\n",
    "    env.set_error_type(label)\n",
    "    rl = PolicyGradient(env.n_features, env.n_actions)\n",
    "    rl.load(model_path) #your_trained_model your_trained_model_skip\n",
    "    \n",
    "    net_time = 0\n",
    "    step_time = 0\n",
    "    start_ = time.time()\n",
    "    eva = []\n",
    "    buffer_size = int(ratio*len(env.ori_traj_set[0]))\n",
    "    if buffer_size < 3:\n",
    "        return\n",
    "    steps, observation = env.reset(0, buffer_size)\n",
    "    for index in range(buffer_size, steps):\n",
    "        if index == steps - 1:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        start = time.time()\n",
    "        action = rl.quick_time_action(observation)\n",
    "        net_time += float(time.time()-start)\n",
    "        start = time.time()\n",
    "        observation_, _ = env.step(0, action, index, done, 'V') #'T' means Training, and 'V' means Validation\n",
    "        step_time += float(time.time()-start)\n",
    "        observation = observation_\n",
    "    eva=env.output(0, 'V') #'T' means Training, 'V' means Validation, and 'V-VIS' for visualization on Validation\n",
    "    print(\"Effectiveness: %e\" %eva)\n",
    "    print(\"Training elapsed time = %s\", float(time.time() - start_))\n",
    "    print(\"net_time:\",net_time)\n",
    "    print(\"step_time:\",step_time)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8e67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multitrain(ratio, label):\n",
    "    train(traj_amount=200, valid_amount=70, Round=3, show_time=100, ratio=ratio, a_size=3, s_size=3, skip_size=2, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffaa74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It cost 1390.849925994873s\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "t = time.time()\n",
    "parallel = Parallel(n_jobs=-1, backend='loky', timeout=7200)\n",
    "err_type = ['sed','ped','dad','sad','sed','ped','dad','sad']\n",
    "ratio_type = [0.1,0.1,0.1,0.1,0.2,0.2,0.2,0.2]\n",
    "out = parallel(delayed(multitrain)(ratio, label) for ratio, label in zip(ratio_type, err_type))\n",
    "print('It cost {}s'.format(time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e36d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow1]",
   "language": "python",
   "name": "conda-env-tensorflow1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
